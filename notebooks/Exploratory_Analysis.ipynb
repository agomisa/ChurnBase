{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26a84945-c00c-4808-82db-42a67f613535",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96050ca0-6b4c-4bdd-8876-833ba183348b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2146976d-4921-4c31-9c85-7ae017800da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffa066f0-4c8a-488c-bb7b-958c8d26446d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"projectviews.default.gold_daily_projectviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73a4bd28-9f7a-4ec3-8167-8b15c7e51c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab5a264e-9f81-4392-a4ab-e8fd6507e142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4.1 Engagement KPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfcf18f5-ab15-44ba-bdd5-b0f534b9d75c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**DAU / WAU / MAU (Views)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a192217-d5ec-462a-9ab9-5173c7123396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_engagement_kpis(df):\n",
    "    \"\"\"\n",
    "    Calculate and plot DAU, WAU, MAU trends.\n",
    "\n",
    "    DataFrame must have:\n",
    "        - event_date (date or string)\n",
    "        - count_views (numeric)\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.withColumn(\"event_date\", F.to_date(\"event_date\"))\n",
    "\n",
    "    dau_df = (df.groupBy(\"event_date\")\n",
    "                .agg(F.sum(\"count_views\").alias(\"DAU_views\"))\n",
    "                .orderBy(\"event_date\"))\n",
    "\n",
    "    df_week = df.withColumn(\"week\", F.date_trunc(\"week\", \"event_date\"))\n",
    "    wau_df = (df_week.groupBy(\"week\")\n",
    "                .agg(F.sum(\"count_views\").alias(\"WAU_views\"))\n",
    "                .orderBy(\"week\"))\n",
    "\n",
    "    df_month = df.withColumn(\"month\", F.date_trunc(\"month\", \"event_date\"))\n",
    "    mau_df = (df_month.groupBy(\"month\")\n",
    "                .agg(F.sum(\"count_views\").alias(\"MAU_views\"))\n",
    "                .orderBy(\"month\"))\n",
    "\n",
    "    dau_pd = dau_df.toPandas()\n",
    "    wau_pd = wau_df.toPandas()\n",
    "    mau_pd = mau_df.toPandas()\n",
    "\n",
    "    dau_pd[\"event_date\"] = pd.to_datetime(dau_pd[\"event_date\"])\n",
    "    wau_pd[\"week\"] = pd.to_datetime(wau_pd[\"week\"])\n",
    "    mau_pd[\"month\"] = pd.to_datetime(mau_pd[\"month\"])\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(dau_pd[\"event_date\"], dau_pd[\"DAU_views\"], marker='o', label=\"DAU\")\n",
    "    plt.title(\"Daily Active Views Trend\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Views\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(wau_pd[\"week\"], wau_pd[\"WAU_views\"], marker='o', label=\"WAU\")\n",
    "    plt.title(\"Weekly Active Views Trend\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Views\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return dau_pd, wau_pd, mau_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e513a0f-3ca4-4d20-abf3-f43fb3092087",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dau_pd, wau_pd, mau_pd = plot_engagement_kpis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67f4e75e-b81f-4819-b34e-0998194b0b1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Session-length (Proxy)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "752874f9-16b4-46ea-8f46-66656f37fd0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"domain_code\").orderBy(\"event_date\")\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .withColumn(\"event_date\", F.to_date(\"event_date\"))\n",
    "    .withColumn(\"is_active\", (F.col(\"count_views\") > 0).cast(\"int\"))\n",
    "    .withColumn(\"streak_group\", F.sum(F.when(F.col(\"is_active\") == 0, 1).otherwise(0)).over(w))\n",
    "    .withColumn(\"streak_len\", \n",
    "                F.when(F.col(\"is_active\") == 1,\n",
    "                        F.row_number().over(Window.partitionBy(\"domain_code\", \"streak_group\").orderBy(\"event_date\")))\n",
    "                .otherwise(0)\n",
    "                )\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate: average & median streak length per date\n",
    "\n",
    "agg_df = df.groupBy(\"event_date\").agg(\n",
    "    F.avg(\"streak_len\").alias(\"avg_streak\"),\n",
    "    F.expr(\"percentile_approx(streak_len, 0.5)\").alias(\"median_streak\")\n",
    ").orderBy(\"event_date\")\n",
    "\n",
    "agg_pd = agg_df.toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(agg_pd[\"event_date\"], agg_pd[\"avg_streak\"], label=\"Average Streak Length\")\n",
    "plt.plot(agg_pd[\"event_date\"], agg_pd[\"median_streak\"], label=\"Median Streak Length\", linestyle=\"--\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Streak Length (days)\")\n",
    "plt.title(\"Average & Median Streak Length Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52cd4bb4-f78e-4bcc-82a6-a837b253dbec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "agg_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42c07d49-6dd7-4283-b8c8-9eab1b95bff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Content Diversity (Domain Diversity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32b7e1f1-b1fe-4b3f-987e-ed7ba04523e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Total views per day\n",
    "daily_total = df.groupBy(\"event_date\").agg(\n",
    "    F.sum(\"count_views\").alias(\"total_views\")\n",
    ")\n",
    "\n",
    "df_div = df.join(daily_total, on=\"event_date\", how=\"left\")\n",
    "df_div = df_div.withColumn(\n",
    "    \"p_d\",\n",
    "    F.col(\"count_views\") / F.col(\"total_views\")\n",
    ")\n",
    "\n",
    "# HHI per day\n",
    "hhi_df = df_div.groupBy(\"event_date\").agg(\n",
    "    F.sum(F.pow(F.col(\"p_d\"), 2)).alias(\"HHI\"))\n",
    "\n",
    "# Diversity = 1 - HHI\n",
    "hhi_df = hhi_df.withColumn(\n",
    "    \"diversity\",\n",
    "    F.lit(1) - F.col(\"HHI\")\n",
    "    )\n",
    "\n",
    "hhi_df.orderBy(\"event_date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bffb513-8b55-4086-aad9-d553cda0b88a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4.2 Data quirks and mitigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d5dd5e9-abb3-4a6f-9cf3-9ac60f3c17e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_engagement_kpis_with_quirks(dau_pd, wau_pd, mau_pd):\n",
    "    \"\"\"\n",
    "    Highlight possible data quirks (seasonality, sparsity, spikes).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Detect quirks ---\n",
    "\n",
    "    quirks = {}\n",
    "\n",
    "    ###################################\n",
    "    # 1. Sparsity: days with zero views\n",
    "    ###################################\n",
    "\n",
    "    # Define the full date range from the min to the max date in your data\n",
    "    min_date = dau_pd['event_date'].min()\n",
    "    max_date = dau_pd['event_date'].max()\n",
    "    full_dates = pd.date_range(start=min_date, end=max_date)\n",
    "\n",
    "    # Days with zero views\n",
    "    zero_days_df = dau_pd[dau_pd[\"DAU_views\"] == 0]\n",
    "\n",
    "    # Days missing from the dataset\n",
    "    missing_days = full_dates.difference(dau_pd['event_date'])\n",
    "\n",
    "    quirks[\"sparsity_zero_views\"] = zero_days_df[\"event_date\"].tolist()\n",
    "    quirks[\"sparsity_missing_days\"] = missing_days.tolist()\n",
    "\n",
    "    print(\"Days with zero views:\", quirks[\"sparsity_zero_views\"])\n",
    "    print(\"Days missing from dataset:\", quirks[\"sparsity_missing_days\"])\n",
    "\n",
    "    #############################################\n",
    "    # 2. Spikes: values greater than mean + 3*std\n",
    "    #############################################\n",
    "\n",
    "    threshold = dau_pd[\"DAU_views\"].mean() + 3 * dau_pd[\"DAU_views\"].std()\n",
    "    spikes_df = dau_pd[dau_pd[\"DAU_views\"] > threshold]\n",
    "    quirks[\"spikes\"] = spikes_df[\"event_date\"].tolist()\n",
    "\n",
    "    #####################\n",
    "    # 3. Seasonality hint\n",
    "    #####################\n",
    "\n",
    "    weekly_avg = dau_pd.groupby(dau_pd[\"event_date\"].dt.dayofweek)[\"DAU_views\"].mean()\n",
    "    quirks[\"seasonality\"] = weekly_avg.to_dict()\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.plot(dau_pd[\"event_date\"], dau_pd[\"DAU_views\"], marker='o', label=\"DAU\")\n",
    "    plt.plot(wau_pd[\"week\"], wau_pd[\"WAU_views\"], marker='s', label=\"WAU\")\n",
    "    plt.plot(mau_pd[\"month\"], mau_pd[\"MAU_views\"], marker='^', label=\"MAU\")\n",
    "\n",
    "    # Mark zero days\n",
    "    plt.scatter(zero_days_df[\"event_date\"], zero_days_df[\"DAU_views\"], color='red', label=\"Zero days\", zorder=5)\n",
    "\n",
    "    # Mark spikes\n",
    "    plt.scatter(spikes_df[\"event_date\"], spikes_df[\"DAU_views\"], color='orange', label=\"Spikes\", zorder=5)\n",
    "\n",
    "    plt.title(\"Engagement KPIs with Data Quirks Highlighted\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Views\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # --- Print quirks summary ---\n",
    "    print(\"\\n=== Data Quirks Detected ===\")\n",
    "    print(f\"1. Sparsity (zero days): {quirks['sparsity_zero_views']}\")\n",
    "    print(f\"   Missing days: {quirks['sparsity_missing_days']}\")\n",
    "    print(f\"2. Spikes: {quirks['spikes']}\")\n",
    "    print(\"3. Seasonality pattern (avg views by weekday):\")\n",
    "    for day, avg in quirks[\"seasonality\"].items():\n",
    "        print(f\"   Day {day} (0=Mon): {avg:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc4a4d1b-4716-47af-a422-327d18c0c301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_engagement_kpis_with_quirks(dau_pd, wau_pd, mau_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "035bf91b-a326-4265-921c-afec5d3e9252",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Average Views by Weekday**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efe82e6c-182e-4399-8143-70b2013fad38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_avg_views_by_weekday(df, date_col=\"event_date\", views_col=\"count_views\"):\n",
    "    \"\"\"\n",
    "    Calculate average views by weekday and plot the result.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Spark DataFrame with at least two columns: a date column and a views count column.\n",
    "    - date_col: Name of the date column in df (default \"event_date\").\n",
    "    - views_col: Name of the views count column in df (default \"count_views\").\n",
    "    \"\"\"\n",
    "\n",
    "    # Add a weekday number column (Monday=0, Sunday=6)\n",
    "    df_with_weekday = df.withColumn(\n",
    "        \"weekday\",\n",
    "        ((F.dayofweek(F.col(date_col)) + 5) % 7)\n",
    "    ).withColumn(\n",
    "        \"weekday_name\",\n",
    "        F.when(F.col(\"weekday\") == 0, \"Monday\")\n",
    "         .when(F.col(\"weekday\") == 1, \"Tuesday\")\n",
    "         .when(F.col(\"weekday\") == 2, \"Wednesday\")\n",
    "         .when(F.col(\"weekday\") == 3, \"Thursday\")\n",
    "         .when(F.col(\"weekday\") == 4, \"Friday\")\n",
    "         .when(F.col(\"weekday\") == 5, \"Saturday\")\n",
    "         .when(F.col(\"weekday\") == 6, \"Sunday\")\n",
    "    )\n",
    "\n",
    "    # Aggregate average views by weekday name\n",
    "    agg_df = df_with_weekday.groupBy(\"weekday_name\") \\\n",
    "        .agg(F.avg(views_col).alias(\"avg_views\"))\n",
    "\n",
    "    # Collect to pandas\n",
    "    pdf = agg_df.toPandas()\n",
    "\n",
    "    # Order the days of the week properly\n",
    "    order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    pdf['weekday_name'] = pd.Categorical(pdf['weekday_name'], categories=order, ordered=True)\n",
    "    pdf = pdf.sort_values('weekday_name')\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(pdf['weekday_name'], pdf['avg_views'], color='skyblue')\n",
    "    plt.title('Average Views by Weekday')\n",
    "    plt.xlabel('Weekday')\n",
    "    plt.ylabel('Average Views')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "plot_avg_views_by_weekday(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57d6d6ea-f46d-4a4a-b9bb-905ef457ea8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Trend One domain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f153774-dc6e-4f8b-99aa-73b7ac1e7fe2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Example domain"
    }
   },
   "outputs": [],
   "source": [
    "df_dom = df.toPandas()\n",
    "\n",
    "# Ensure event_date is in datetime format\n",
    "df_dom[\"event_date\"] = pd.to_datetime(df_dom[\"event_date\"], errors=\"coerce\")\n",
    "\n",
    "# Filter for the given domain_code\n",
    "df_dom = df_dom.loc[df_dom[\"domain_code\"] == 'ab.m.d'].sort_values(by='event_date').reset_index(drop=True)\n",
    "\n",
    "# Plot with label for legend\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_dom[\"event_date\"], df_dom[\"count_views\"], marker='o', label='ab.m.d')\n",
    "plt.title(\"Daily Active Views Trend for ab.m.d\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Views\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d0f5cde-f8fc-48f7-98c0-b970d18640e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 4.3 Missing dates for each domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b2862ae-2c4b-49a7-bfd2-b0db06e0921f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"domain_code\").orderBy(\"event_date\")\n",
    "gaps_df = (\n",
    "    df\n",
    "    .withColumn(\"prev_date\", F.lag(\"event_date\").over(w)) \n",
    "    .withColumn(\"gap_days\", F.datediff(\"event_date\", \"prev_date\")) \n",
    "    .filter(F.col(\"prev_date\").isNotNull() & (F.col(\"gap_days\") > 1))\n",
    ")\n",
    "print(f'Found {gaps_df.count()} gaps')\n",
    "\n",
    "\n",
    "per_dom = df.groupBy(\"domain_code\").agg(\n",
    "    F.min(\"event_date\").alias(\"start_date\"),\n",
    "    F.max(\"event_date\").alias(\"end_date\")\n",
    ")\n",
    "expanded = (\n",
    "    per_dom\n",
    "    .withColumn(\n",
    "        \"event_date\",\n",
    "        F.explode(F.sequence(\"start_date\", \"end_date\", F.expr(\"interval 1 day\")))\n",
    "    )\n",
    "    .select(\"domain_code\", \"event_date\")\n",
    ")\n",
    "\n",
    "patched = (\n",
    "    expanded\n",
    "    .join(df, [\"domain_code\", \"event_date\"], \"left\") \n",
    "    .withColumn(\"is_missing\", F.when(F.col(\"count_views\").isNull(), True).otherwise(False))\n",
    "    .withColumn(\"count_views\", F.coalesce(F.col(\"count_views\"), F.lit(0)).cast(\"long\"))\n",
    ")\n",
    "\n",
    "missing_summary = (\n",
    "    patched\n",
    "    .filter(F.col('is_missing') == True)  \n",
    "    .groupBy(\"domain_code\")\n",
    "    .agg(\n",
    "        F.count(\"event_date\").alias(\"missing_count\"),\n",
    "        F.sort_array(\n",
    "            F.collect_set(F.date_format(F.col(\"event_date\"), \"yyyy-MM-dd\"))\n",
    "        ).alias(\"missing_dates\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a47b806-fcc0-4301-82c1-12760592f6e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "missing_summary.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "03a4cfc5-7a0e-4d9a-b8e9-95ef16ece479",
     "origId": 7929021206374446,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7869073159749014,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Exploratory_Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
